<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
  <title>Data Tables</title>
  <meta name="slug" content="data-table">
  <meta name="toRoot" content="..">
  <link rel="shortcut icon" type="image/x-icon" href="../../favicon.ico">
  <link href="../../static/fonts.css" rel="stylesheet" type="text/css">
  <link href="../../static/site.css" rel="stylesheet" type="text/css">
  <script>const NUMBERING = {"vol1":"1","systems-programming":"2","async-programming":"3","unit-test":"4","file-backup":"5","data-table":"6","pattern-matching":"7","regex-parser":"8","page-templates":"9","build-manager":"10","layout-engine":"11","file-interpolator":"12","module-loader":"13","style-checker":"14","code-generator":"15","doc-generator":"16","module-bundler":"17","package-manager":"18","virtual-machine":"19","debugger":"20","text-editor":"21","conclusion":"22","bib":"A","license":"B","conduct":"C","contributing":"D","cognition":"E","gloss":"F","links":"G","authors":"H"}</script>
  <script src="../../static/site.js"></script>
  <script>window.onload = () => fixPage()</script>
</head>
<body id="_top">
<nav>
<div class="row">
<div class="left2">
<a href="../"><img src="../../static/logo.svg" alt="site logo" class="site-logo"/></a>
</div>
<div class="right2">
<div class="dropdown">
<span class="navtitle">▿ Sections</span>
<div class="dropdown-content" id="Sections">
</div>
</div>
<div class="dropdown">
<span class="navtitle">▿ Chapters</span>
<div class="dropdown-content" id="Chapters">
<a href="../systems-programming/"><span class="nowrap">Systems Programming</span></a>
<br/><a href="../async-programming/"><span class="nowrap">Asynchronous Programming</span></a>
<br/><a href="../unit-test/"><span class="nowrap">Unit Testing</span></a>
<br/><a href="../file-backup/"><span class="nowrap">File Backup</span></a>
<br/><a href="../data-table/"><span class="nowrap">Data Tables</span></a>
<br/><a href="../pattern-matching/"><span class="nowrap">Pattern Matching</span></a>
<br/><a href="../regex-parser/"><span class="nowrap">Parsing Expressions</span></a>
<br/><a href="../page-templates/"><span class="nowrap">Page Templates</span></a>
<br/><a href="../build-manager/"><span class="nowrap">Build Manager</span></a>
<br/><a href="../layout-engine/"><span class="nowrap">Layout Engine</span></a>
<br/><a href="../file-interpolator/"><span class="nowrap">File Interpolator</span></a>
<br/><a href="../module-loader/"><span class="nowrap">Module Loader</span></a>
<br/><a href="../style-checker/"><span class="nowrap">Style Checker</span></a>
<br/><a href="../code-generator/"><span class="nowrap">Code Generator</span></a>
<br/><a href="../doc-generator/"><span class="nowrap">Documentation Generator</span></a>
<br/><a href="../module-bundler/"><span class="nowrap">Module Bundler</span></a>
<br/><a href="../package-manager/"><span class="nowrap">Package Manager</span></a>
<br/><a href="../virtual-machine/"><span class="nowrap">Virtual Machine</span></a>
<br/><a href="../debugger/"><span class="nowrap">Debugger</span></a>
<br/><a href="../text-editor/"><span class="nowrap">Text Editor</span></a>
<br/><a href="../conclusion/"><span class="nowrap">Conclusion</span></a>
</div>
</div>
<div class="dropdown">
<span class="navtitle">▿ Appendices</span>
<div class="dropdown-content" id="Appendices">
<a href="../bib/"><span class="nowrap">Bibliography</span></a>
<br/><a href="../license/"><span class="nowrap">License</span></a>
<br/><a href="../conduct/"><span class="nowrap">Code of Conduct</span></a>
<br/><a href="../contributing/"><span class="nowrap">Contributing</span></a>
<br/><a href="../cognition/"><span class="nowrap">Cognition</span></a>
<br/><a href="../gloss/"><span class="nowrap">Glossary</span></a>
<br/><a href="../links/"><span class="nowrap">Links</span></a>
<br/><a href="../authors/"><span class="nowrap">Authors</span></a>
</div>
</div>
</div>
</div>
</nav>
  <main>
  <h1>Data Tables</h1>
  <h2 class="lede">Loading, saving, and manipulating tables efficiently</h2>
<div class="callout">
  <p>Terms defined: <g key="column_major">column-major storage</g>, <g key="data_frame">data frame</g>, <g key="heterogeneous">heterogeneous</g>, <g key="homogeneous">homogeneous</g>, <g key="immutable">immutable</g>, <g key="row_major">row-major storage</g>, <g key="sql">SQL</g>, <g key="tagged_data">tagged data</g>, <g key="test_harness">test harness</g></p>
</div>
<p>In <x key="file-backup">the previous chapter</x> we said that
operations in memory are thousands of times faster than operations that touch the filesystem,
but how accurate is that?
More generally,
given two ways to implement something,
how can we tell which is the most efficient?</p>
<p>The simplest way is usually to conduct some experiments.
To see how to do this,
we will take a look several ways to implement data tables
(sometimes called <g key="data_frame">data frames</g>)
like those in R's <a href="https://www.tidyverse.org/">tidyverse</a>,
Python's <a href="https://pandas.pydata.org/">Pandas</a> library,
or the <a href="http://www.data-forge-js.com/">DataForge</a> library for JavaScript.
A data table has one or more named columns and zero or more rows;
each row has one value for each column,
and all the values in a column have the same type
(<f key="data-table-conceptual"></f>).</p>
<figure id="data-table-conceptual" class="fixme"><img src="/static/tools-small.jpg" alt="Data table structure"/><figcaption>The structure of a data table.</figcaption></figure>
<p>The key operations on data tables are the same as those in <g key="sql">SQL</g>:
filter, select, summarize, and join.
These can be implemented in about 1000 lines of code,
but their performance depends on how the data table is stored.</p>
<h2 id="how-can-we-implement-data-tables">How can we implement data tables?</h2>
<p>One way to store a table is <g key="row_major">row-major</g> order,
in which the values in each row are stored together in memory.
This is sometimes also called <g key="heterogeneous">heterogeneous</g> storage
because each &quot;unit&quot; of storage can contain values of different types.
In JavaScript,
we implement this as an array of objects
(<f key="data-table-storage-order"></f>).</p>
<p>Another option is <g key="column_major">column-major</g> or <g key="homogeneous">homogeneous</g> order,
in which all the values in a column are stored together.
In JavaScript,
this could be implemented using an object
whose members are all arrays of the same length.</p>
<figure id="data-table-storage-order" class="fixme"><img src="/static/tools-small.jpg" alt="Row-major vs. column-major storage order"/><figcaption>Row-major storage vs. column-major storage for data tables.</figcaption></figure>
<p>To find out which is better
we will construct one of each,
try some operations,
record their execution times and memory use,
and then compare them.
The answer will depend on both the implementations
and on what mix of operations we measure:
for example,
if one strategy works better for filter and another for select,
the ratio of filters to selects may determine which is &quot;best&quot;.</p>
<div class="callout">
<h3 id="immutability">Immutability</h3>
<p>All of our implementations will treat each data table as <g key="immutable">immutable</g>:
once we have created it,
we will not modify its contents.
This makes the programming easier
(and safer, since shared data structures are a rich source of bugs),
and doesn't actually have much impact on performance.
For example,
if we filter a data table stored in column major order,
we can either move elements in memory to fill the holes created by deleted rows,
or copy the values we want to keep to a new block of contiguous storage.</p>
</div>
<p>For our first experiment,
let's build a row-major table with some number of columns.
To keep it simple,
we will repeat the values 0, 1, and 2 to fill the table.</p>
<pre title="build.js"><code class="language-js">export const buildRows = (nRows, labels) =&gt; {
  const result = []
  for (let iR = 0; iR &lt; nRows; iR += 1) {
    const row = {}
    labels.forEach(label =&gt; {
      row[label] = iR
    })
    result.push(row)
  }
  return result
}</code></pre>
<p>Next,
we write <code>filter</code> and <code>select</code> for tables laid out this way.
We need to provide a callback function to <code>filter</code> to determine which rows to keep
like the callback for <code>Array.filter</code>;
for selecting columns,
we provide a list of the keys that identify the columns we want to keep.
We expect filtering to be relatively fast,
since it is recycling rows,
while selecting should be relatively slow,
since we have to construct a new set of arrays
(<f key="data-table-row-ops"></f>).</p>
<pre title="table-performance.js"><code class="language-js">const rowFilter = (table, func) =&gt; {
  return table.filter(row =&gt; func(row))
}

const rowSelect = (table, toKeep) =&gt; {
  return table.map(row =&gt; {
    const newRow = {}
    toKeep.forEach(label =&gt; {
      newRow[label] = row[label]
    })
    return newRow
  })
}</code></pre>
<figure id="data-table-row-ops" class="fixme"><img src="/static/tools-small.jpg" alt="Row-major operations"/><figcaption>Operations on row-major data tables.</figcaption></figure>
<p>Now let's do the same for column-major storage.
Building the object that holds the columns is straightforward:</p>
<pre title="build.js"><code class="language-js">export const buildCols = (nRows, labels) =&gt; {
  const result = {}
  labels.forEach(label =&gt; {
    result[label] = []
    for (let iR = 0; iR &lt; nRows; iR += 1) {
      result[label].push(iR)
    }
  })
  return result
}</code></pre>
<p>Filtering is more complex,
since the values in each row are scattered across several arrays,
but selecting is just a matter of recycling the arrays we want in the new table.
We expect selecting to be relatively fast,
since only the references to the columns need to be copied,
but filtering will be relatively slow since we are constructing multiple new arrays
(<f key="data-table-col-ops"></f>).</p>
<pre title="table-performance.js"><code class="language-js">const colFilter = (table, func) =&gt; {
  const result = {}
  const labels = Object.keys(result)
  labels.forEach(label =&gt; {
    result[label] = []
  })
  for (let iR = 0; iR &lt; table.label_1.length; iR += 1) {
    if (func(table, iR)) {
      labels.forEach(label =&gt; {
        result[label].push(table[label][iR])
      })
    }
  }
  return result
}

const colSelect = (table, toKeep) =&gt; {
  const result = {}
  toKeep.forEach(label =&gt; {
    result[label] = table[label]
  })
  return result
}</code></pre>
<figure id="data-table-col-ops" class="fixme"><img src="/static/tools-small.jpg" alt="Column-major operations"/><figcaption>Operations on column-major data tables.</figcaption></figure>
<div class="callout">
<h3 id="not-quite-polymorphic">Not quite polymorphic</h3>
<p>Our tests would be simpler to write if the two versions of <code>filter</code> and <code>select</code>
took exactly the same parameters,
but the row-testing functions for <code>filter</code> are different
because of the differences in the ways the tables are stored.
We could force them to be the same by (for example)
packing the values for each row in the column-major implementation
into a temporary object
and passing that to the same filtering function we used for the row-major implementation,
but that extra work would bias the performance comparison in row-major's favor.</p>
</div>
<h2 id="how-can-we-test-the-performance-of-our-implementations">How can we test the performance of our implementations?</h2>
<p>Now that we have our tables and operations,
we can build a <g key="test_harness">test harness</g> to run those operations
on data tables of varying sizes.
We arbitrarily decide to keep half of the columns and one-third of the rows;
these ratios will affect our decision about which is better,
so if we were doing this for a real application we would test what happens
as these fractions vary.
And as we said earlier,
the relative performance will depend on the ratio of filters to selects;
our balance should be based on data from whatever application we intend to support.</p>
<p>Our performance measurement program looks like this:</p>
<pre title="table-performance.js"><code class="language-js">const RANGE = 3

const main = () =&gt; {
  const nRows = parseInt(process.argv[2])
  const nCols = parseInt(process.argv[3])
  const filterPerSelect = parseFloat(process.argv[4])

  const labels = [...Array(nCols).keys()].map(i =&gt; `label_${i + 1}`)
  const someLabels = labels.slice(0, Math.floor(labels.length / 2))
  assert(someLabels.length &gt; 0,
    'Must have some labels for select (array too short)')

  const [rowTable, rowSize, rowHeap] = memory(buildRows, nRows, labels)
  const [colTable, colSize, colHeap] = memory(buildCols, nRows, labels)

  const rowFilterTime =
    time(rowFilter, rowTable,
      row =&gt; ((row.label_1 % RANGE) === 0))
  const rowSelectTime =
    time(rowSelect, rowTable, someLabels)
  const colFilterTime =
    time(colFilter, colTable,
      (table, iR) =&gt; ((table.label_1[iR] % RANGE) === 0))
  const colSelectTime =
    time(colSelect, colTable, someLabels)

  const ratio = calculateRatio(filterPerSelect,
    rowFilterTime, rowSelectTime,
    colFilterTime, colSelectTime)

  const result = {
    nRows,
    nCols,
    filterPerSelect,
    rowSize,
    rowHeap,
    colSize,
    colHeap,
    rowFilterTime,
    rowSelectTime,
    colFilterTime,
    colSelectTime,
    ratio
  }
  console.log(yaml.safeDump(result))
}</code></pre>
<p>The functions that actually do the measurements
use the <a href="https://www.npmjs.com/package/microtime"><code>microtime</code></a> library to get microsecond level timing
because JavaScript's <code>Date</code> only gives us millisecond-level resolution.
We use <a href="https://www.npmjs.com/package/object-sizeof"><code>object-sizeof</code></a> to estimate memory how much memory our structures require;
We also call <code>process.memoryUsage()</code> and look at the <code>heapUsed</code> value,
but it may be affected by <a href="#garbage_collection">garbage collection</a> and a host of other factors.</p>
<pre title="table-performance.js"><code class="language-js">const memory = (func, ...params) =&gt; {
  const before = process.memoryUsage()
  const result = func(...params)
  const after = process.memoryUsage()
  const heap = after.heapUsed - before.heapUsed
  const size = sizeof(result)
  return [result, size, heap]
}

const time = (func, ...params) =&gt; {
  const before = microtime.now()
  func(...params)
  const after = microtime.now()
  return after - before
}

const calculateRatio = (f2S, rFilterT, rSelectT, cFilterT, cSelectT) =&gt; {
  return ((f2S * rFilterT) + rSelectT) / ((f2S * cFilterT) + cSelectT)
}</code></pre>
<p>Let's run our program for a table with 100 rows and 3 columns and a 3:1 ratio of filter to select:</p>
<pre title="table-performance-100-03-03.sh"><code class="language-sh">node table-performance.js 100 3 3
</code></pre>
<pre title="table-performance-100-03-03.out"><code class="language-out">nRows: 100
nCols: 3
filterPerSelect: 3
rowSize: 6600
rowHeap: 26512
colSize: 2442
colHeap: 8536
rowFilterTime: 62
rowSelectTime: 88
colFilterTime: 110
colSelectTime: 39
ratio: 0.7425474254742548
</code></pre>
<div class="continue">
<p>What if we increase the table size to 10,000 rows by 30 columns with the same 3:1 filter/select ratio?</p>
</div>
<pre title="table-performance-10000-30-03.out"><code class="language-out">nRows: 10000
nCols: 30
filterPerSelect: 3
rowSize: 7020000
rowHeap: 18413464
colSize: 2400462
colHeap: -3198584
rowFilterTime: 1622
rowSelectTime: 11386
colFilterTime: 4680
colSelectTime: 88
ratio: 1.1503397508493771
</code></pre>
<div class="continue">
<p>And if we keep the table size the same but use a 10:1 filter/select ratio?</p>
</div>
<pre title="table-performance-10000-30-10.out"><code class="language-out">nRows: 10000
nCols: 30
filterPerSelect: 10
rowSize: 7020000
rowHeap: 18325136
colSize: 2400462
colHeap: -3375072
rowFilterTime: 2339
rowSelectTime: 11790
colFilterTime: 3498
colSelectTime: 65
ratio: 1.0038521900413753
</code></pre>
<figure id="data-table-performance" class="fixme"><img src="/static/tools-small.jpg" alt="Performance of data table operations"/><figcaption>Relative performance of operations on row-major and column-major data tables.</figcaption></figure>
<p>The results in <f key="data-table-performance"></f> show that column-major storage is better.
It uses less memory (presumably because labels aren't duplicated),
and the time required to construct new objects when doing select with row-major storage
outweighs cost of appending to arrays when doing filter with column-major storage.
Unfortunately,
the code for column-major storage is a little more complicated to write,
which is a cost that doesn't show up in experiments.</p>
<h2 id="what-is-the-most-efficient-way-to-save-a-table">What is the most efficient way to save a table?</h2>
<p>Our data tables are going to be stored in files of some kind.
If one storage scheme is much more efficient than another and we are reading or writing frequently,
that could change our mind about how to implement them.
Two simple text-based schemes are row-oriented and column-oriented <a href="#json">JSON</a>,
i.e.,
we just print the data structures we have.</p>
<p>Let's run the 10,000×30 test:</p>
<pre title="storage-performance-10000-30.out"><code class="language-out">nRows: 10000
nCols: 30
rowStringTime: 50909
rowStringSize: 9393402
colStringTime: 11607
colStringSize: 2934164
</code></pre>
<p>The time needed for the row-major version is almost ten times greater than
that needed for the column-major version;
again,
we assume that the redundant printing of the labels is at least partly to blame.</p>
<p>If that diagnosis is correct,
then a packed version of row-major storage ought to be faster.
We save the column headers once,
then copy the data values into an array of arrays and save that:</p>
<pre title="packed-rows.js"><code class="language-js">const asPackedJson = (table) =&gt; {
  const temp = {}
  temp.keys = Object.keys(table[0])
  temp.values = table.map(row =&gt; temp.keys.map(k =&gt; row[k]))
  return JSON.stringify(temp)
}</code></pre>
<pre title="packed-rows-10000-30.out"><code class="language-out">nRows: 10000
nCols: 30
packedRowStringTime: 26858
packedRowStringSize: 2974084
</code></pre>
<p>These results show that packing the rows takes less time
than turning the data structure we have into a string.
Again,
we assume this is because copying data takes less time than turning labels into strings over and over,
but column-major storage is still the best approach.</p>
<h2 id="does-binary-storage-improve-performance">Does binary storage improve performance?</h2>
<p>Let's try one more strategy for storing our tables.
JavaScript stores values in <g key="tagged_data">tagged</g> data structures:
some bits define the value's type,
and other bits store the actual data
(<f key="data-table-object-storage"></f>).</p>
<figure id="data-table-object-storage" class="fixme"><img src="/static/tools-small.jpg" alt="JavaScript object storage"/><figcaption>How JavaScript uses tagged data structures to store objects.</figcaption></figure>
<p>We can save space by keeping track of the types ourselves
and just storing the bits that represent the values.
JavaScript has an <code>ArrayBuffer</code> class for exactly this purpose.
It stores any value we want as a set of bits;
we then access those bits through a view that presents the data as a particular type,
such as unsigned 8-bit integer or 64-bit float
(<f key="data-table-packed-storage"></f>).</p>
<figure id="data-table-packed-storage" class="fixme"><img src="/static/tools-small.jpg" alt="Packing objects for storage"/><figcaption>Storing object values as bits with lookup information.</figcaption></figure>
<p>To store a column-major table,
we will fill an <code>ArrayBuffer</code> with:</p>
<ol>
<li>
<p>Two integers that hold the table's dimensions.</p>
</li>
<li>
<p>A string with the labels joined by newline characters.
(We use newlines as a separator because we assume column labels can't contain them.)</p>
</li>
<li>
<p>The numbers themselves.</p>
</li>
</ol>
<pre title="packed-cols.js"><code class="language-js">const asBinary = (table) =&gt; {
  const labels = Object.keys(table)

  const nCols = labels.length
  const nRows = table[labels[0]].length
  const dimensions = new Uint32Array([nCols, nRows])

  const allLabels = labels.join('\n')
  const encoder = new TextEncoder()
  const encodedLabels = encoder.encode(allLabels)

  const dataSize = sizeof(0) * nCols * nRows
  const totalSize =
    dimensions.byteLength + encodedLabels.byteLength + dataSize

  const buffer = new ArrayBuffer(totalSize)
  const result = new Uint8Array(buffer)
  result.set(dimensions, 0)
  result.set(encodedLabels, dimensions.byteLength)

  let current = dimensions.byteLength + encodedLabels.byteLength
  labels.forEach(label =&gt; {
    const temp = new Float64Array(table[label])
    result.set(temp, current)
    current += temp.byteLength
  })

  return result
}</code></pre>
<pre title="packed-cols-10000-30.out"><code class="language-out">nRows: 10000
nCols: 30
packedColBinaryTime: 4740
packedColBinarySize: 2400268
</code></pre>
<p>Packing the data table saves time
because copying bits is faster than turning numbers into characters,
but it doesn't save as much space as expected.
The reason is that double-precision numbers are 8 bytes long,
but because we have chosen simple integer values for our tests,
they can be represented by just 5 characters (which is 10 bytes).
If we had &quot;real&quot; numbers,
the storage benefit would probably be more pronounced.</p>
<h2 id="exercises">Exercises</h2>
<h3 class="exercise">Varying filter behavior</h3>
<p>How does our decision about which storage format is better change
if we keep 1% of rows when filtering instead of one third?
What if we keep 90% of rows?</p>
<h3 class="exercise">Filtering by strings</h3>
<p>Modify the comparison of filter and select to work with tables
that contain columns of strings instead of columns of numbers
and see how that changes performance.
For testing,
creating random 4-letter strings using the characters A-Z
and then filter by:</p>
<ul>
<li>an exact match,</li>
<li>strings starting with a specific character, and</li>
<li>strings that contain a specific character</li>
</ul>
<h3 class="exercise">Join performance</h3>
<p>A <g key="join">join</g> combines data from two tables based on matching keys.
For example,
if the two tables are:</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Left</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>a1</td>
</tr>
<tr>
<td>B</td>
<td>b1</td>
</tr>
<tr>
<td>C</td>
<td>c1</td>
</tr>
</tbody>
</table>
<div class="continue">
<p>and:</p>
</div>
<table>
<thead>
<tr>
<th>Key</th>
<th>Right</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>a2</td>
</tr>
<tr>
<td>A</td>
<td>a3</td>
</tr>
<tr>
<td>B</td>
<td>b2</td>
</tr>
</tbody>
</table>
<div class="continue">
<p>then the join is:</p>
</div>
<table>
<thead>
<tr>
<th>Key</th>
<th>Left</th>
<th>Right</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>a1</td>
<td>a2</td>
</tr>
<tr>
<td>A</td>
<td>a1</td>
<td>a3</td>
</tr>
<tr>
<td>B</td>
<td>b1</td>
<td>b2</td>
</tr>
</tbody>
</table>
<p>Write a test to compare the performance of row-wise vs. column-wise storage
when joining two tables based on matching numeric keys.
Does the answer depend on the fraction of keys that match?</p>
<h3 class="exercise">Join optimization</h3>
<p>The simplest way to <g key="join">join</g> two tables is
to look for matching keys using a double loop.
An alternative is to build an <g key="index_database">index</g> for each table
and then use it to construct matches.
For example, suppose the tables are:</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Left</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>a1</td>
</tr>
<tr>
<td>B</td>
<td>b1</td>
</tr>
<tr>
<td>C</td>
<td>c1</td>
</tr>
</tbody>
</table>
<div class="continue">
<p>and:</p>
</div>
<table>
<thead>
<tr>
<th>Key</th>
<th>Right</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>a2</td>
</tr>
<tr>
<td>A</td>
<td>a3</td>
</tr>
<tr>
<td>B</td>
<td>b2</td>
</tr>
</tbody>
</table>
<p>The first step is to create a <code>Map</code> showing where each key is found in the first table:</p>
<pre><code class="language-js">{A: [0], B: [1], C: [2]}
</code></pre>
<div class="continue">
<p>The second step is to create a similar <code>Map</code> for the second table:</p>
</div>
<pre><code class="language-js">{A: [0, 1], B: [2]}
</code></pre>
<div class="continue">
<p>We can then loop over the keys in one of the maps,
look up values in the second map,
and construct all of the matches.</p>
</div>
<p>Write a function that joins two tables this way.
Is it faster or slower than using a double loop?
How does the answer depend on the number of keys and the fraction that match?</p>
<h3 class="exercise">Flipping storage</h3>
<p>Our tests showed that storing row-oriented tables as JSON
is much slower than storing column-oriented tables.
Write a test to determine whether converting a row-oriented table to a column-oriented table
and then saving the latter
is faster than saving the row-oriented table directly.</p>
<h3 class="exercise">Sparse storage</h3>
<p>A <g key="sparse_matrix">sparse matrix</g> is one in which most of the values are zero.
Instead of storing them all,
a program can use a map to store non-zero values
and a lookup function to return zero for anything that isn't stored explicitly:</p>
<pre><code class="language-js">def spareMatrixGet(matrix, row, col) =&gt; {
  return matrix.contains(row, col)
    ? matrix.get(row, col)
    : 0
}
</code></pre>
<p>The same technique can be used if most of the entries in a data table are missing.
Write a function that creates a sparse table in which a random 5% of the values are non-zero
and the other 95% are zero,
then compare the memory requirements and performance of filter and select for this implementation
versus those of row-wise and column-wise storage.</p>
<h3 class="exercise">Loading time</h3>
<p>Modify the programs in this section to measure the time required to convert a data table from JSON or binary form
back to a data structure.</p>
<h3 class="exercise">Saving fixed-width strings</h3>
<p>To improve performance,
databases often store <g key="fixed_width_string">fixed-width</g> strings,
i.e.,
they limit the length of the strings in a column to some fixed size
and <g key="pad_string">pad</g> strings that are shorter than that.</p>
<ol>
<li>
<p>Write a function that takes an array of strings and an integer with
and creates an <code>ArrayBuffer</code> containing the strings padded to that width.
The function should throw an exception if any of the strings
are longer than the specified width.</p>
</li>
<li>
<p>Write another function that takes an <code>ArrayBuffer</code> as input
and returns an array of strings.
This function should remove the padding
so that strings shorter than the fixed width are restored to their original form.</p>
</li>
</ol>
<h3 class="exercise">Saving variable-width strings</h3>
<p><g key="fixed_width_string">Fixed-width</g> storage is inefficient for large blocks of text
such as contracts, novels, and resumés,
since padding every document to the length of the longest will probably waste a lot of space.
An alternative way to store these in binary is to save each entry as a (length, text) pair.</p>
<div class="fixme">
<p>Diagram of (length, text) pairs.</p>
</div>
<ol>
<li>
<p>Write a function that takes a list of strings as input
and returns an <code>ArrayBuffer</code> containing (length, text) pairs.</p>
</li>
<li>
<p>Write another function that takes such an <code>ArrayBuffer</code>
and returns an array containing the original text.</p>
</li>
<li>
<p>Write tests with Mocha to confirm that your functions work correctly.</p>
</li>
</ol>
<h3 class="exercise">ASCII storage</h3>
<p>The original <g key="ascii">ASCII</g> standard specified
a 7-bit <g key="character_encoding">character encoding</g> for letters commonly used in English,
and many data files still only use characters whose numeric codes are in the range 0-127.</p>
<ol>
<li>
<p>Write a function that takes an array of single-letter strings
and returns an <code>ArrayBuffer</code> that stores them using one byte per character
if all of the characters will fit into 7 bits,
and multiple bytes per character if any of the characters require more than 7 bits.</p>
</li>
<li>
<p>Write another function that takes an <code>ArrayBuffer</code> generated by the first function
and re-creates the array of characters.
The function must <em>only</em> take the <code>ArrayBuffer</code> as an argument,
so the first element of the <code>ArrayBuffer</code> should indicate
how to interpret the rest of its contents.</p>
</li>
<li>
<p>Write tests with Mocha to check that your functions work correctly.</p>
</li>
</ol>
</main>
<footer>
<div class="row">
<div class="left3">
<a href="../file-backup/"><em>&laquo; File Backup</em></a>
</div>
<div class="middle3">
<a href="../license/"><img class="footer" src="../../static/cc-by.svg" alt="License" /></a>
<a href="https://github.com/software-tools-in-javascript/stjs/"><img class="footer" src="../../static/github.svg" alt="Repository" /></a>
© 2020 <a href="../authors/">The Authors</a>
</div>
<div class="right3">
<a href="../pattern-matching/"><em>Pattern Matching &raquo;</em></a>
</div>
</div>
</footer>
</body>
</html>
