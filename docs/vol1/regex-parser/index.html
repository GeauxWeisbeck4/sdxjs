<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
  <title>Parsing Expressions</title>
  <meta name="slug" content="regex-parser">
  <meta name="toRoot" content="../..">
  <meta name="toVolume" content="..">
  <meta name="volume" content="vol1">
  <link rel="shortcut icon" type="image/x-icon" href="../../favicon.ico">
  <link href="../../static/fonts.css" rel="stylesheet" type="text/css">
  <link href="../../static/site.css" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" type="image/x-icon" href="../../favicon.ico">
  <link rel="alternate" type="application/atom+xml" title="Software Tools in JavaScript" href="https://stjs.tech/atom.xml">
  <script>const NUMBERING = {"vol1-intro":"1","systems-programming":"2","async-programming":"3","unit-test":"4","file-backup":"5","data-table":"6","pattern-matching":"7","regex-parser":"8","page-templates":"9","build-manager":"10","layout-engine":"11","file-interpolator":"12","module-loader":"13","style-checker":"14","code-generator":"15","doc-generator":"16","module-bundler":"17","package-manager":"18","virtual-machine":"19","debugger":"20","vol1-finale":"21","bib":"A","license":"B","conduct":"C","contributing":"D","gloss":"E","links":"F","authors":"G"}</script>
  <script src="../../static/site.js"></script>
  <script>window.onload = () => fixPage(true)</script>
</head>
<body id="_top">
<nav>
<div class="row">
<div class="left2">
<a href="../../"><img src="../../static/logo.svg" alt="site logo" class="site-logo"/></a>
<a href="../../">Software Tools in JavaScript</a>
</div>
<div class="right2">
<div class="dropdown">
<span class="navtitle">▿ Sections</span>
<div class="dropdown-content" id="Sections">
</div>
</div>
<div class="dropdown">
<span class="navtitle">▿ Chapters</span>
<div class="dropdown-content" id="Chapters">
<a href="../vol1-intro/"><span class="nowrap">Introduction</span></a>
<br/><a href="../systems-programming/"><span class="nowrap">Systems Programming</span></a>
<br/><a href="../async-programming/"><span class="nowrap">Asynchronous Programming</span></a>
<br/><a href="../unit-test/"><span class="nowrap">Unit Testing</span></a>
<br/><a href="../file-backup/"><span class="nowrap">File Backup</span></a>
<br/><a href="../data-table/"><span class="nowrap">Data Tables</span></a>
<br/><a href="../pattern-matching/"><span class="nowrap">Pattern Matching</span></a>
<br/><a href="../regex-parser/"><span class="nowrap">Parsing Expressions</span></a>
<br/><a href="../page-templates/"><span class="nowrap">Page Templates</span></a>
<br/><a href="../build-manager/"><span class="nowrap">Build Manager</span></a>
<br/><a href="../layout-engine/"><span class="nowrap">Layout Engine</span></a>
<br/><a href="../file-interpolator/"><span class="nowrap">File Interpolator</span></a>
<br/><a href="../module-loader/"><span class="nowrap">Module Loader</span></a>
<br/><a href="../style-checker/"><span class="nowrap">Style Checker</span></a>
<br/><a href="../code-generator/"><span class="nowrap">Code Generator</span></a>
<br/><a href="../doc-generator/"><span class="nowrap">Documentation Generator</span></a>
<br/><a href="../module-bundler/"><span class="nowrap">Module Bundler</span></a>
<br/><a href="../package-manager/"><span class="nowrap">Package Manager</span></a>
<br/><a href="../virtual-machine/"><span class="nowrap">Virtual Machine</span></a>
<br/><a href="../debugger/"><span class="nowrap">Debugger</span></a>
<br/><a href="../vol1-finale/"><span class="nowrap">Finale</span></a>
</div>
</div>
<div class="dropdown">
<span class="navtitle">▿ Appendices</span>
<div class="dropdown-content" id="Appendices">
<a href="../bib/"><span class="nowrap">Bibliography</span></a>
<br/><a href="../license/"><span class="nowrap">License</span></a>
<br/><a href="../conduct/"><span class="nowrap">Code of Conduct</span></a>
<br/><a href="../contributing/"><span class="nowrap">Contributing</span></a>
<br/><a href="../gloss/"><span class="nowrap">Glossary</span></a>
<br/><a href="../links/"><span class="nowrap">Links</span></a>
<br/><a href="../authors/"><span class="nowrap">Authors</span></a>
</div>
</div>
</div>
</div>
</nav>
  <main>
  <h1>Parsing Expressions</h1>
  <h2 class="lede">Turning text into code</h2>
<div class="callout">
  <p class="callout">
    <strong>Terms defined:</strong>
    <g key="fsm">finite state machine</g>, <g key="literal">literal</g>, <g key="parser">parser</g>, <g key="precedence">precedence</g>, <g key="token">token</g>, <g key="turing_machine">Turing Machine</g>, <g key="well_formed">well formed</g>, <g key="yaml">YAML</g>
  </p>
</div>
<p>In <x key="pattern-matching"></x> we created regular expressions by constructing objects.
It takes a lot less typing to write them as strings,
as we did for HTML selectors,
but if we're going to do that we need something to convert those strings to the required objects.
We need to write a <g key="parser">parser</g>.
Here is the grammar we will handle:</p>
<table id="regex-parser-grammar-codes"><caption>Regular expression grammar.</caption>
<thead>
<tr>
<th>Meaning</th>
<th>Character</th>
</tr>
</thead>
<tbody>
<tr>
<td>Any literal character <em>c</em></td>
<td><em>c</em></td>
</tr>
<tr>
<td>Beginning of input</td>
<td>^</td>
</tr>
<tr>
<td>End of input</td>
<td>$</td>
</tr>
<tr>
<td>Zero or more of the previous thing</td>
<td>*</td>
</tr>
<tr>
<td>Either/or</td>
<td>|</td>
</tr>
<tr>
<td>Grouping</td>
<td>(…)</td>
</tr>
</tbody>
</table>
<p>When we are done
we should be able to parse <code>/^(a|b|$)*z$/</code> as
&quot;start of text&quot;,
&quot;any number of 'a', 'b', or '$'&quot;,
&quot;a single 'z',
and &quot;end of text&quot;.
(We write regular expressions inside slashes to distinguish them from strings.)
To keep things simple,
we will create a tree of objects (<f key="regex-parser-expression-tree"></f>)
rather than instances of the regular expression classes from <x key="pattern-matching"></x>;
the exercises will tackle the latter.</p>
<figure id="regex-parser-expression-tree"><img src="./figures/expression-tree.svg" alt="Expression tree for regular expression" latexscale="true"/><figcaption>Representing the result of parsing a regular expression as an tree.</figcaption></figure>
<div class="callout">
<h3 id="please-dont-write-parsers">Please don't write parsers</h3>
<p>Languages that are comfortable for people to read are usually difficult for computers to understand
and vice versa,
so we need parsers to translate human-friendly notation into computer-friendly representations.
However,
the world doesn't need more file formats;
if you need a configuration file or lookup table,
please use CSV, JSON, <g key="yaml">YAML</g>,
or something else that already has an acronym
rather than inventing a format of your own.</p>
</div>
<h2 id="how-can-we-break-text-into-tokens">How can we break text into tokens?</h2>
<p>A <g key="token">token</g> is an atom of text,
such as the digits making up a number or the letters making up a variable name.
In our grammar the tokens are the special characters <code>*</code>, <code>|</code>, <code>(</code>, <code>)</code>, <code>^</code>, and <code>$</code>,
plus any sequence of one or more other characters (which count as one multi-letter token).
This classification guides the design of our parser:</p>
<ol>
<li>
<p>If a character is special, create a token for it.</p>
</li>
<li>
<p>If it is a <g key="literal">literal</a> then:</p>
<ol>
<li>combine it with the current literal if there is one, or</li>
<li>start a new literal.</li>
</ol>
</li>
<li>
<p>Since <code>^</code> and <code>$</code> are either special or regular depending on position,
we must treat them as separate tokens or as part of a literal
based on where they appear.</p>
</li>
</ol>
<p>We can translate these rules almost directly into code
to create a list of objects whose keys are <code>kind</code> and <code>loc</code> (short for location),
with the extra key <code>value</code> for literal values:</p>
<pre title="tokenizer-collapse.js"><code class="language-js">const SIMPLE = {
  '*': 'Any',
  '|': 'Alt',
  '(': 'GroupStart',
  ')': 'GroupEnd'
}

const tokenize = (text) =&gt; {
  const result = []
  for (let i = 0; i &lt; text.length; i += 1) {
    const c = text[i]
    if (c in SIMPLE) {
      result.push({ kind: SIMPLE[c], loc: i })
    } else if (c === '^') {
      if (i === 0) {
        result.push({ kind: 'Start', loc: i })
      } else {
        combineOrPush(result, c, i)
      }
    } else if (c === '$') {
      if (i === (text.length - 1)) {
        result.push({ kind: 'End', loc: i })
      } else {
        combineOrPush(result, c, i)
      }
    } else {
      combineOrPush(result, c, i)
    }
  }

  return result
}
...
export default tokenize
</code></pre>
<p>The helper function <code>combineOrPush</code> does exactly what its name says.
If the thing most recently added to the list of tokens isn't a literal,
the new character becomes a new token;
otherwise,
we append the new character to the literal we're building:</p>
<pre title="tokenizer-collapse.js"><code class="language-js">const combineOrPush = (soFar, character, location) =&gt; {
  const topIndex = soFar.length - 1
  if ((soFar.length === 0) || (soFar[topIndex].token !== 'Lit')) {
    soFar.push({ kind: 'Lit', value: character, loc: location })
  } else {
    soFar[topIndex].value += character
  }
}</code></pre>
<p>We can try this out with a three-line test program:</p>
<pre title="tokenizer-collapse-example.js"><code class="language-js">import tokenize from './tokenizer-collapse.js'

const test = '^a^b*'
const result = tokenize(test)
console.log(JSON.stringify(result, null, 2))
</code></pre>
<pre title="tokenizer-collapse-example.out"><code class="language-out">[
  {
    "kind": "Start",
    "loc": 0
  },
  {
    "kind": "Lit",
    "value": "a",
    "loc": 1
  },
  {
    "kind": "Lit",
    "value": "^",
    "loc": 2
  },
  {
    "kind": "Lit",
    "value": "b",
    "loc": 3
  },
  {
    "kind": "Any",
    "loc": 4
  }
]
</code></pre>
<p>This simple tokenizer is readable, efficient, and wrong.
The problem is that the expression <code>/ab*/</code> means &quot;a single <code>a</code> followed by zero or more <code>b</code>&quot;.
If we combine the <code>a</code> and <code>b</code> as we read them,
though,
we wind up with &quot;zero or more repetitions of <code>ab</code>&quot;.
(Don't feel bad if you didn't spot this:
we didn't notice the problem until we were implementing the next step.)</p>
<p>The solution is to treat each regular character as its own literal in this stage
and then combine things later.
Doing this lets us get rid of the nested <code>if</code> for handling <code>^</code> and <code>$</code> as well:</p>
<pre title="tokenizer.js"><code class="language-js">const SIMPLE = {
  '*': 'Any',
  '|': 'Alt',
  '(': 'GroupStart',
  ')': 'GroupEnd'
}

const tokenize = (text) =&gt; {
  const result = []
  for (let i = 0; i &lt; text.length; i += 1) {
    const c = text[i]
    if (c in SIMPLE) {
      result.push({ kind: SIMPLE[c], loc: i })
    } else if ((c === '^') &amp;&amp; (i === 0)) {
      result.push({ kind: 'Start', loc: i })
    } else if ((c === '$') &amp;&amp; (i === (text.length - 1))) {
      result.push({ kind: 'End', loc: i })
    } else {
      result.push({ kind: 'Lit', loc: i, value: c })
    }
  }

  return result
}

export default tokenize
</code></pre>
<p>Software isn't done until it's tested,
so let's build some <a href="https://mochajs.org/">Mocha</a> tests for our tokenizer.
The listing below shows a few of these
along with the output for the full set:</p>
<pre title="test/test-tokenizer.js"><code class="language-js">import assert from 'assert'

import tokenize from '../tokenizer.js'

describe('tokenizes correctly', async () =&gt; {
  it('tokenizes a single character', () =&gt; {
    assert.deepStrictEqual(tokenize('a'), [
      { kind: 'Lit', value: 'a', loc: 0 }
    ])
  })

  it('tokenizes a sequence of characters', () =&gt; {
    assert.deepStrictEqual(tokenize('ab'), [
      { kind: 'Lit', value: 'a', loc: 0 },
      { kind: 'Lit', value: 'b', loc: 1 }
    ])
  })

  it('tokenizes start anchor alone', () =&gt; {
    assert.deepStrictEqual(tokenize('^'), [
      { kind: 'Start', loc: 0 }
    ])
  })

  it('tokenizes start anchor followed by characters', () =&gt; {
    assert.deepStrictEqual(tokenize('^a'), [
      { kind: 'Start', loc: 0 },
      { kind: 'Lit', value: 'a', loc: 1 }
    ])
  })
...
  it('tokenizes a complex expression', () =&gt; {
    assert.deepStrictEqual(tokenize('^a*(bcd|e^)*f$gh$'), [
      { kind: 'Start', loc: 0 },
      { kind: 'Lit', loc: 1, value: 'a' },
      { kind: 'Any', loc: 2 },
      { kind: 'GroupStart', loc: 3 },
      { kind: 'Lit', loc: 4, value: 'b' },
      { kind: 'Lit', loc: 5, value: 'c' },
      { kind: 'Lit', loc: 6, value: 'd' },
      { kind: 'Alt', loc: 7 },
      { kind: 'Lit', loc: 8, value: 'e' },
      { kind: 'Lit', loc: 9, value: '^' },
      { kind: 'GroupEnd', loc: 10 },
      { kind: 'Any', loc: 11 },
      { kind: 'Lit', loc: 12, value: 'f' },
      { kind: 'Lit', loc: 13, value: '$' },
      { kind: 'Lit', loc: 14, value: 'g' },
      { kind: 'Lit', loc: 15, value: 'h' },
      { kind: 'End', loc: 16 }
    ])
  })
})
</code></pre>
<pre title="tokenizer-test.out"><code class="language-out">
&gt; stjs@1.0.0 test /u/stjs
&gt; mocha */test/test-*.js "-g" "tokenizes correctly"



  tokenizes correctly
    ✓ tokenizes a single character
    ✓ tokenizes a sequence of characters
    ✓ tokenizes start anchor alone
    ✓ tokenizes start anchor followed by characters
    ✓ tokenizes circumflex not at start
    ✓ tokenizes start anchor alone
    ✓ tokenizes end anchor preceded by characters
    ✓ tokenizes dollar sign not at end
    ✓ tokenizes repetition alone
    ✓ tokenizes repetition in string
    ✓ tokenizes repetition at end of string
    ✓ tokenizes alternation alone
    ✓ tokenizes alternation in string
    ✓ tokenizes alternation at start of string
    ✓ tokenizes the start of a group alone
    ✓ tokenizes the start of a group in a string
    ✓ tokenizes the end of a group alone
    ✓ tokenizes the end of a group at the end of a string
    ✓ tokenizes a complex expression


  19 passing (8ms)
</code></pre>
<h2 id="how-can-we-turn-a-list-of-tokens-into-a-tree">How can we turn a list of tokens into a tree?</h2>
<p>We now have a list of tokens,
but we need a tree that captures the nesting introduced by parentheses
and the way that <code>*</code> applies to whatever comes before it.
Let's trace a few cases in order to see how to build this tree:</p>
<ol>
<li>
<p>If the regular expression is <code>/a/</code>, we create a <code>Lit</code> token for the letter <code>a</code>
(where &quot;create&quot; means &quot;append to the output list&quot;).</p>
</li>
<li>
<p>What if the regular expression is <code>/a*/</code>?
We first create a <code>Lit</code> token for the <code>a</code> and append it to the output list.
When we see the <code>*</code>,
we take that <code>Lit</code> token off the tail of the output list
and replace it with an <code>Any</code> token that has the <code>Lit</code> token as its child.</p>
</li>
<li>
<p>Our next thought experiment is <code>/(ab)/</code>.
We don't know how long the group is going to be when we see the <code>(</code>,
so we put the parenthesis onto the output as a marker.
We then add the <code>Lit</code> tokens for the <code>a</code> and <code>b</code>
until we see the <code>)</code>,
at which point we pull tokens off the end of the output list
until we get back to the <code>(</code> marker.
When we find it,
we put everything we have temporarily collected into a <code>Group</code> token and append it to the output list.
This algorithm automatically handles <code>/(a*)/</code> and <code>/(a(b*)c)/</code>.</p>
</li>
<li>
<p>What about <code>/a|b/</code>?
We append a <code>Lit</code> token for <code>a</code>, get the <code>|</code> and---and we're stuck,
because we don't yet have the next token we need to finish building the <code>Alt</code>.</p>
</li>
</ol>
<p>One way to solve this problem is to check to see if the thing on the top of the stack is waiting to combine
each time we append a new token.
However,
this doesn't handle <code>/a|b*/</code> properly.
The pattern is supposed to mean &quot;one <code>a</code> or any number of <code>b</code>&quot;,
but the check-and-combine strategy will turn it into the equivalent of <code>/(a|b)*/</code>.</p>
<p>A better (i.e., correct) solution is
to leave some partially-completed tokens in the output and compress them later
(<f key="regex-parser-mechanics"></f>).
If our input is the pattern <code>/a|b/</code>, we can:</p>
<ol>
<li>
<p>Append a <code>Lit</code> token for <code>a</code>.</p>
</li>
<li>
<p>When we see <code>|</code>,
make that <code>Lit</code> token the left child of the <code>Alt</code>
and append that without filling in the right child.</p>
</li>
<li>
<p>Append the <code>Lit</code> token for <code>b</code>.</p>
</li>
<li>
<p>After all tokens have been handled,
look for partially-completed <code>Alt</code> tokens and make whatever comes after them their right child.</p>
</li>
</ol>
<p>Again, this automatically handles patterns like <code>/(ab)|c*|(de)/</code>.</p>
<figure id="regex-parser-mechanics"><img src="./figures/mechanics.svg" alt="Mechanics of combining tokens" latexscale="true"/><figcaption>Mechanics of combining tokens while parsing regular expressions.</figcaption></figure>
<p>It's time to turn these ideas into code.
The main structure of our parser is:</p>
<pre title="parser.js"><code class="language-js">import assert from 'assert'

import tokenize from './tokenizer.js'

const parse = (text) =&gt; {
  const result = []
  const allTokens = tokenize(text)
  for (let i = 0; i &lt; allTokens.length; i += 1) {
    const token = allTokens[i]
    const last = i === allTokens.length - 1
    handle(result, token, last)
  }
  return compress(result)
}
...
export default parse
</code></pre>
<p>We handle tokens case by case
(with a few assertions to check that patterns are <g key="well_formed">well formed</g>):</p>
<pre title="parser.js"><code class="language-js">const handle = (result, token, last) =&gt; {
  if (token.kind === 'Lit') {
    result.push(token)
  } else if (token.kind === 'Start') {
    assert(result.length === 0,
      'Should not have start token after other tokens')
    result.push(token)
  } else if (token.kind === 'End') {
    assert(last,
      'Should not have end token before other tokens')
    result.push(token)
  } else if (token.kind === 'GroupStart') {
    result.push(token)
  } else if (token.kind === 'GroupEnd') {
    result.push(groupEnd(result, token))
  } else if (token.kind === 'Any') {
    assert(result.length &gt; 0,
      `No operand for '*' (location ${token.loc})`)
    token.child = result.pop()
    result.push(token)
  } else if (token.kind === 'Alt') {
    assert(result.length &gt; 0,
      `No operand for '*' (location ${token.loc})`)
    token.left = result.pop()
    token.right = null
    result.push(token)
  } else {
    assert(false, 'UNIMPLEMENTED')
  }
}</code></pre>
<p>When we find the <code>)</code> that marks the end of a group,
we take items from the end of the output list
until we find the matching start
and use them to create a group:</p>
<pre title="parser.js"><code class="language-js">const groupEnd = (result, token) =&gt; {
  const group = {
    kind: 'Group',
    loc: null,
    end: token.loc,
    children: []
  }
  while (true) {
    assert(result.length &gt; 0,
           `Unmatched end parenthesis (location ${token.loc})`)
    const child = result.pop()
    if (child.kind === 'GroupStart') {
      group.loc = child.loc
      break
    }
    group.children.unshift(child)
  }
  return group
}</code></pre>
<p>Finally,
when we have finished with the input,
we go through the output list one last time to fill in the right side of <code>Alt</code>s:</p>
<pre title="parser.js"><code class="language-js">const compress = (raw) =&gt; {
  const cooked = []
  while (raw.length &gt; 0) {
    const token = raw.pop()
    if (token.kind === 'Alt') {
      assert(cooked.length &gt; 0,
             `No right operand for alt (location ${token.loc})`)
      token.right = cooked.shift()
    }
    cooked.unshift(token)
  }
  return cooked
}</code></pre>
<p>Once again,
it's not done until we've tested it:</p>
<pre title="test/test-parser.js"><code class="language-js">import assert from 'assert'

import parse from '../parser.js'

describe('parses correctly', async () =&gt; {
  it('parses the empty string', () =&gt; {
    assert.deepStrictEqual(parse(''), [])
  })

  it('parses a single literal', () =&gt; {
    assert.deepStrictEqual(parse('a'), [
      { kind: 'Lit', loc: 0, value: 'a' }
    ])
  })

  it('parses multiple literals', () =&gt; {
    assert.deepStrictEqual(parse('ab'), [
      { kind: 'Lit', loc: 0, value: 'a' },
      { kind: 'Lit', loc: 1, value: 'b' }
    ])
  })
...
  it('parses alt of groups', () =&gt; {
    assert.deepStrictEqual(parse('a|(bc)'), [
      {
        kind: 'Alt',
        loc: 1,
        left: { kind: 'Lit', loc: 0, value: 'a' },
        right: {
          kind: 'Group',
          loc: 2,
          end: 5,
          children: [
            { kind: 'Lit', loc: 3, value: 'b' },
            { kind: 'Lit', loc: 4, value: 'c' }
          ]
        }
      }
    ])
  })
})
</code></pre>
<pre title="parser-test.out"><code class="language-out">
&gt; stjs@1.0.0 test /u/stjs
&gt; mocha */test/test-*.js "-g" "parses correctly"



  parses correctly
    ✓ parses the empty string
    ✓ parses a single literal
    ✓ parses multiple literals
    ✓ parses start anchors
    ✓ handles circumflex not at start
    ✓ parses end anchors
    ✓ parses circumflex not at start
    ✓ parses empty groups
    ✓ parses groups containing characters
    ✓ parses two groups containing characters
    ✓ parses any
    ✓ parses any of group
    ✓ parses alt
    ✓ parses alt of any
    ✓ parses alt of groups


  15 passing (9ms)
</code></pre>
<p>While our final parser is less than 90 lines of code,
it is doing a lot of complex things.
Compared to parsers for things like JSON and YAML,
though,
it is still very simple.
If we have more operators with different <g key="precedence">precedences</g>
we should switch to the <a href="https://en.wikipedia.org/wiki/Shunting-yard_algorithm">shunting-yard algorithm</a>,
and if we need to handle a language like JavaScript we should explore tools like <a href="https://www.antlr.org/">ANTLR</a>,
which can generate a parser automatically given a description of the language to be parsed.
As we said at the start,
though,
if our design requires us to write a parser we should try to come up with a better design.
CSV, JSON, YAML, and other formats <a href="https://third-bit.com/2015/06/11/why-we-cant-have-nice-things/">have their quirks</a>,
but at least they're broken the same way everywhere.</p>
<div class="callout">
<h3 id="the-limits-of-computing">The limits of computing</h3>
<p>One of the most important theoretical results in computer science is that
every formal language corresponds to a type of abstract machine and vice versa,
and that some languages (or machines) are more or less powerful than others.
For example,
every regular expression corresponds to a <g key="fsm">finite state machine</g> (FSM)
like the one in <f key="regex-parser-finite-state-machine"></f>.
As powerful as FSMs are,
they cannot match things like nested parentheses or HTML tags,
and <a href="https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454">attempting to do so is a sin</a>.
If you add a stack to the system you can process a much richer set of languages,
and if you add two stacks you have something equivalent to a <g key="turing_machine">Turing Machine</g>
that can do any conceivable computation.
<cite>Conery2021</cite> presents this idea and others for self-taught developers.</p>
</div>
<figure id="regex-parser-finite-state-machine"><img src="./figures/finite-state-machine.svg" alt="Finite state machine" latexscale="true"/><figcaption>A finite state machine equivalent to a regular expression.</figcaption></figure>
<h2 id="exercises">Exercises</h2>
<h3 class="exercise">Create objects</h3>
<p>Modify the parser to return instances of classes derived from <code>RegexBase</code>.</p>
<h3 class="exercise">Escape characters</h3>
<p>Modify the parser to handle escape characters,
so that (for example) <code>\*</code> is interpreted as &quot;a literal '*' character&quot;
and <code>\\</code> is interpreted as &quot;a literal backslash&quot;.</p>
<h3 class="exercise">Lazy matching</h3>
<p>Modify the parser so that <code>*?</code> is interpreted as a single token
meaning &quot;lazy match zero or more&quot;.</p>
<h3 class="exercise">Character sets</h3>
<p>Modify the parser so that expressions like <code>[xyz]</code> are interpreted to mean
&quot;match any one of the characters 'x', 'y', or 'z'&quot;.</p>
<h3 class="exercise">Back reference</h3>
<p>Modify the tokenizer so that it recognizes <code>\1</code>, <code>\2</code>, and so on to mean &quot;back reference&quot;.
The number may contain any number of digits.</p>
<h3 class="exercise">Named groups</h3>
<ol>
<li>
<p>Modify the tokenizer to recognize named groups.
For example, the named group <code>/(?&lt;triple&gt;aaa)/</code>
would create a named group called <code>triple</code> that matches exactly three consecutive occurrences of 'a'.</p>
</li>
<li>
<p>Write Mocha tests for your modified tokenizer.
Does it handle nested named groups?</p>
</li>
</ol>
<h3 class="exercise">Object streams</h3>
<p>Write a parser that turns files of key-value pairs separated by blank lines into objects.
For example, if the input is:</p>
<pre><code class="language-txt">left: &quot;left value&quot;
first: 1

middle: &quot;middle value&quot;
second: 2

right: &quot;right value&quot;
third: 3
</code></pre>
<div class="continue">
<p>then the output will be:</p>
</div>
<pre><code class="language-js">[
  {left: &quot;left value&quot;, first: 1},
  {middle: &quot;middle value&quot;, second: 2},
  {right: &quot;right value&quot;, third: 3}
]
</code></pre>
<p>Keys are always upper- and lower-case characters;
values may be strings in double quotes or unquoted numbers.</p>
<h3 class="exercise">Tokenize HTML</h3>
<ol>
<li>
<p>Write a tokenizer for a subset of HTML that consists of:</p>
<ul>
<li>Opening tags without attributes, such as <code>&lt;div&gt;</code> and <code>&lt;p&gt;</code></li>
<li>Closing tags, such as <code>&lt;/p&gt;</code> and <code>&lt;/div&gt;</code></li>
<li>Plain text between tags that does <em>not</em> contain '&lt;' or '&gt;' characters</li>
</ul>
</li>
<li>
<p>Modify the tokenizer to handle <code>key=&quot;value&quot;</code> attributes in opening tags.</p>
</li>
<li>
<p>Write Mocha tests for your tokenizer.</p>
</li>
</ol>
<h3 class="exercise">The Shunting Yard Algorithm</h3>
<ol>
<li>
<p>Use the <a href="https://en.wikipedia.org/wiki/Shunting-yard_algorithm">shunting-yard algorithm</a>
to implement a tokenizer for a simple subset of arithmetic that includes:</p>
<ul>
<li>single-letter variable names</li>
<li>single-digit numbers</li>
<li>the <code>+</code>, <code>*</code>, and <code>^</code> operators, where <code>+</code> has the lowest precedence and <code>^</code> has the highest</li>
</ul>
</li>
<li>
<p>Write Mocha tests for your tokenizer.</p>
</li>
</ol>
<h3 class="exercise">Handling errors</h3>
<ol>
<li>
<p>What does the regular expression tokenizer do
with expressions that contain unmatched opening parentheses like <code>/a(b/</code>?
What about expressions that contain unmatched closing parentheses like <code>/ab)/</code>?</p>
</li>
<li>
<p>Modify it so it produces a more useful error message.</p>
</li>
</ol>
</main>
<footer>
<div class="row">
<div class="left3">
<a href="../pattern-matching/"><em>&laquo; Pattern Matching</em></a>
</div>
<div class="middle3">
<a href="../license/"><img class="footer" src="../../static/cc-by.svg" alt="License" /></a>
<a href="https://github.com/software-tools-in-javascript/stjs/"><img class="footer" src="../../static/github.svg" alt="Repository" /></a>
<a href="mailto:info@stjs.tech"><img class="footer" src="../../static/email.svg" alt="Email" /></a>
© 2020 <a href="../authors/">The Authors</a>
</div>
<div class="right3">
<a href="../page-templates/"><em>Page Templates &raquo;</em></a>
</div>
</div>
</footer>
</body>
</html>
