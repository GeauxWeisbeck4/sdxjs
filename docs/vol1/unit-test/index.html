<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
  <title>Unit Testing</title>
  <meta name="slug" content="unit-test">
  <meta name="toRoot" content="..">
  <link rel="shortcut icon" type="image/x-icon" href="../../favicon.ico">
  <link href="../../static/fonts.css" rel="stylesheet" type="text/css">
  <link href="../../static/site.css" rel="stylesheet" type="text/css">
  <script>const NUMBERING = {"vol1":"1","systems-programming":"2","async-programming":"3","unit-test":"4","file-backup":"5","data-table":"6","pattern-matching":"7","regex-parser":"8","page-templates":"9","build-manager":"10","layout-engine":"11","file-interpolator":"12","module-loader":"13","style-checker":"14","code-generator":"15","doc-generator":"16","module-bundler":"17","package-manager":"18","virtual-machine":"19","debugger":"20","conclusion":"21","bib":"A","license":"B","conduct":"C","contributing":"D","cognition":"E","gloss":"F","links":"G","authors":"H"}</script>
  <script src="../../static/site.js"></script>
  <script>window.onload = () => fixPage()</script>
</head>
<body id="_top">
<nav>
<div class="row">
<div class="left2">
<a href="../"><img src="../../static/logo.svg" alt="site logo" class="site-logo"/></a>
</div>
<div class="right2">
<div class="dropdown">
<span class="navtitle">▿ Sections</span>
<div class="dropdown-content" id="Sections">
</div>
</div>
<div class="dropdown">
<span class="navtitle">▿ Chapters</span>
<div class="dropdown-content" id="Chapters">
<a href="../systems-programming/"><span class="nowrap">Systems Programming</span></a>
<br/><a href="../async-programming/"><span class="nowrap">Asynchronous Programming</span></a>
<br/><a href="../unit-test/"><span class="nowrap">Unit Testing</span></a>
<br/><a href="../file-backup/"><span class="nowrap">File Backup</span></a>
<br/><a href="../data-table/"><span class="nowrap">Data Tables</span></a>
<br/><a href="../pattern-matching/"><span class="nowrap">Pattern Matching</span></a>
<br/><a href="../regex-parser/"><span class="nowrap">Parsing Expressions</span></a>
<br/><a href="../page-templates/"><span class="nowrap">Page Templates</span></a>
<br/><a href="../build-manager/"><span class="nowrap">Build Manager</span></a>
<br/><a href="../layout-engine/"><span class="nowrap">Layout Engine</span></a>
<br/><a href="../file-interpolator/"><span class="nowrap">File Interpolator</span></a>
<br/><a href="../module-loader/"><span class="nowrap">Module Loader</span></a>
<br/><a href="../style-checker/"><span class="nowrap">Style Checker</span></a>
<br/><a href="../code-generator/"><span class="nowrap">Code Generator</span></a>
<br/><a href="../doc-generator/"><span class="nowrap">Documentation Generator</span></a>
<br/><a href="../module-bundler/"><span class="nowrap">Module Bundler</span></a>
<br/><a href="../package-manager/"><span class="nowrap">Package Manager</span></a>
<br/><a href="../virtual-machine/"><span class="nowrap">Virtual Machine</span></a>
<br/><a href="../debugger/"><span class="nowrap">Debugger</span></a>
<br/><a href="../conclusion/"><span class="nowrap">Conclusion</span></a>
</div>
</div>
<div class="dropdown">
<span class="navtitle">▿ Appendices</span>
<div class="dropdown-content" id="Appendices">
<a href="../bib/"><span class="nowrap">Bibliography</span></a>
<br/><a href="../license/"><span class="nowrap">License</span></a>
<br/><a href="../conduct/"><span class="nowrap">Code of Conduct</span></a>
<br/><a href="../contributing/"><span class="nowrap">Contributing</span></a>
<br/><a href="../cognition/"><span class="nowrap">Cognition</span></a>
<br/><a href="../gloss/"><span class="nowrap">Glossary</span></a>
<br/><a href="../links/"><span class="nowrap">Links</span></a>
<br/><a href="../authors/"><span class="nowrap">Authors</span></a>
</div>
</div>
</div>
</div>
</nav>
  <main>
  <h1>Unit Testing</h1>
  <h2 class="lede">Testing software piece by piece</h2>
<div class="callout">
  <p>Terms defined: <g key="actual_result">actual result (of test)</g>, <g key="assertion">assertion</g>, <g key="caching">caching</g>, <g key="defensive_programming">defensive programming</g>, <g key="design_pattern">design pattern</g>, <g key="dynamic_loading">dynamic loading</g>, <g key="error_test">error (in a test)</g>, <g key="exception_handler">exception handler</g>, <g key="expected_result">expected result (of test)</g>, <g key="exploratory_programming">exploratory programming</g>, <g key="fail_test">fail (a test)</g>, <g key="fixture">fixture</g>, <g key="global_variable">global variable</g>, <g key="introspection">introspection</g>, <g key="lifecycle">lifecycle</g>, <g key="pass_test">pass (a test)</g>, <g key="side_effect">side effect</g>, <g key="singleton_pattern">Singleton pattern</g>, <g key="test_runner">test runner</g>, <g key="throw_exception">throw (exception)</g>, <g key="unit_test">unit test</g></p>
</div>
<p>We have written many small programs in the previous two chapters,
but haven't really tested any of them.
That's OK for <g key="exploratory_programming">exploratory programming</g>,
but if we are building software that is going to be used instead of just read,
we should try to make sure it works.</p>
<p>A tool for writing and running <g key="unit_test">unit tests</g> is a good first step.
Such a tool should be able to:</p>
<ul>
<li>Find and load files containing tests.</li>
<li>Identify the tests in those files
(which may contain helper functions that aren't actually tests).</li>
<li>Execute the tests and capture results.</li>
<li>Report each test's result and summarize those results.</li>
</ul>
<p>Our design is inspired by tools like <a href="https://mochajs.org/">Mocha</a> and <a href="https://jestjs.io/">Jest</a>,
which were in turn inspired by tools built for languages like Java
<cite>Meszaros2007,Tudose2020</cite>.</p>
<h2 id="how-should-we-handle-unit-testing">How should we handle unit testing?</h2>
<p>As in <a href="https://mochajs.org/">Mocha</a> and other frameworks,
every one of our unit tests will be a function of zero arguments
(so that the framework can run every test the same way).
Each test will create a <g key="fixture">fixture</g> to be tested
and use <g key="assertion">assertions</g>
to compare the <g key="actual_result">actual result</g>
against the <g key="expected_result">expected result</g>.
Each test can have one of three outcomes:</p>
<ul>
<li>
<p><g key="pass_test">Pass</g>: the test's subject works as expected.</p>
</li>
<li>
<p><g key="fail_test">Fail</g>: something is wrong with the test's subject.</p>
</li>
<li>
<p><g key="error_test">Error</g>: something wrong in the testing code itself,
which means we don't know whether the test subject is working properly or not.</p>
</li>
</ul>
<p>To make this work,
we need some way to distinguish failing tests from broken ones.
Our solution relies on the fact that exceptions are objects
and that a program can use <g key="introspection">introspection</g>
to determine the class of an object.
If a test <g key="throw_exception">throws an exception</g>
and that exception's class is <code>assert.AssertionError</code>,
then we will assume the exception came from
one of the assertions we put in the test as a check
(<f key="unit-test-mental-model"></f>).
Any other kind of assertion indicates that the test itself contains an error.</p>
<figure id="unit-test-mental-model"><img src="./figures/mental-model.svg" alt="Mental model of unit testing"/><figcaption>Running tests that can pass, fail, or contain errors.</figcaption></figure>
<h2 id="how-can-we-separate-test-registration-execution-and-reporting">How can we separate test registration, execution, and reporting?</h2>
<p>To start,
let's use a handful of <g key="global_variable">global variables</g> to record tests and their results:</p>
<pre title="dry-run.js"><code class="language-js">// State of tests.
const HopeTests = []
let HopePass = 0
let HopeFail = 0
let HopeError = 0</code></pre>
<p>The function <code>hopeThat</code> saves a descriptive message and a callback function that implements a test
in one of these global variables.
(We don't run tests immediately
because we want to wrap each one in our own <g key="exception_handler">exception handler</g>.)</p>
<pre title="dry-run.js"><code class="language-js">// Record a single test for running later.
const hopeThat = (message, callback) =&gt; {
  HopeTests.push([message, callback])
}</code></pre>
<div class="continue">
<p>Because we're appending tests to an array,
they will be run in the order in which they are registered,
but we shouldn't rely on that.
Every unit test should be independent
so that an error or failure in an early test
doesn't affect the result of a later one.</p>
</div>
<p>Finally,
the function <code>main</code> runs all registered tests:</p>
<pre title="dry-run.js"><code class="language-js">// Run all of the tests that have been asked for and report summary.
const main = () =&gt; {
  HopeTests.forEach(([message, test]) =&gt; {
    try {
      test()
      HopePass += 1
    } catch (e) {
      if (e instanceof assert.AssertionError) {
        HopeFail += 1
      } else {
        HopeError += 1
      }
    }
  })

  console.log(`pass ${HopePass}`)
  console.log(`fail ${HopeFail}`)
  console.log(`error ${HopeError}`)
}</code></pre>
<div class="continue">
<p>If a test completes without an exception, it passes.
If any of the <code>assert</code> calls inside the test raises an <code>AssertionError</code>,
the test fails,
and if it raises any other exception,
it's an error.
After all tests are run,
<code>main</code> reports the number of results of each kind.</p>
</div>
<p>Let's try it out:</p>
<pre title="dry-run.js"><code class="language-js">// Something to test (doesn't handle zero properly).
const sign = (value) =&gt; {
  if (value &lt; 0) {
    return -1
  } else {
    return 1
  }
}

// These two should pass.
hopeThat('Sign of negative is -1', () =&gt; assert(sign(-3) === -1))
hopeThat('Sign of positive is 1', () =&gt; assert(sign(19) === 1))

// This one should fail.
hopeThat('Sign of zero is 0', () =&gt; assert(sign(0) === 0))

// This one is an error.
hopeThat('Sign misspelled is error', () =&gt; assert(sgn(1) === 1))

// Call the main driver.
main()</code></pre>
<pre title="dry-run.out"><code class="language-out">pass 2
fail 1
error 1
</code></pre>
<p>Our simple &quot;framework&quot; does what it's supposed to, but:</p>
<ol>
<li>
<p>It doesn't tell us which tests have passed or failed.</p>
</li>
<li>
<p>Those global variables should be consolidated somehow
so that it's clear they belong together.</p>
</li>
<li>
<p>It doesn't discover tests on its own.</p>
</li>
<li>
<p>We don't have a way to test things that are supposed to raise <code>AssertionError</code>.
Putting assertions into code to check that it is behaving correctly
is called <g key="defensive_programming">defensive programming</g>;
it's a good practice,
but we should make sure those assertions are failing when they're supposed to,
just as we should test our smoke detectors every once in a while.</p>
</li>
</ol>
<h2 id="how-should-we-structure-test-registration">How should we structure test registration?</h2>
<p>The next version of our testing tool solves the first two problems in the original
by putting the testing machinery in a class.
It uses the <g key="singleton_pattern">Singleton</g> <g key="design_pattern">design pattern</g>
to ensure that only one object of that class is ever created.
Singletons are a way to manage related global variables
like the ones we're using to record tests and their results,
and if we change our mind later about only having one instance of the class,
there will be less code to rewrite and re-test.</p>
<p>The file <code>hope.js</code> defines the class and exports one instance of it:</p>
<pre title="hope.js"><code class="language-js">  terse () {
    return this.cases()
      .map(([title, results]) =&gt; `${title}: ${results.length}`)
      .join(' ')
  }

  verbose () {
    let report = ''
    let prefix = ''
    for (const [title, results] of this.cases()) {
      report += `${prefix}${title}:`
      prefix = '\n'
      for (const r of results) {
        report += `${prefix}  ${r}`
      }
    }
    return report
  }

  cases () {
    return [
      ['passes', this.passes],
      ['fails', this.fails],
      ['errors', this.errors]]
  }</code></pre>
<p>This strategy relies on two things:</p>
<ol>
<li>
<p><a href="https://nodejs.org/en/">Node</a> executes the code in a JavaScript module as it loads it,
which means that it runs <code>new Hope()</code> and exports the newly-created object.</p>
</li>
<li>
<p><a href="https://nodejs.org/en/">Node</a> <g key="caching">caches</g> modules,
which means that a given module is only loaded once
no matter how many times it is imported.</p>
</li>
</ol>
<p>Once a program has imported <code>hope</code>,
it can call <code>Hope.test</code> to record a test for later execution
and <code>Hope.run</code> to execute all of the tests registered up until that point
(<f key="unit-test-hope-structure"></f>).</p>
<figure id="unit-test-hope-structure"><img src="./figures/hope-structure.svg" alt="Recording and running tests"/><figcaption>Creating a singleton, recording tests, and running them.</figcaption></figure>
<p>Finally,
our class can reports results as both a terse one-line summary and as a detailed listing.
It can also provide the titles and results of individual tests
so that if someone wants to format them in a different way (e.g., as HTML) they can do so:</p>
<pre title="hope.js"><code class="language-js">  terse () {
    return this.cases()
      .map(([title, results]) =&gt; `${title}: ${results.length}`)
      .join(' ')
  }

  verbose () {
    let report = ''
    let prefix = ''
    for (const [title, results] of this.cases()) {
      report += `${prefix}${title}:`
      prefix = '\n'
      for (const r of results) {
        report += `${prefix}  ${r}`
      }
    }
    return report
  }

  cases () {
    return [
      ['passes', this.passes],
      ['fails', this.fails],
      ['errors', this.errors]]
  }</code></pre>
<div class="callout">
<h3 id="whos-calling">Who's calling?</h3>
<p><code>Hope.test</code> uses the <a href="https://www.npmjs.com/package/caller"><code>caller</code></a> module
to get the name of the function that is registering a test.
Reporting the test's name helps the user figure out where to start debugging,
and getting it via introspection
rather than requiring the user to pass it into the call
reduces typing
and eliminates the problem of a function called <code>test_this</code>
telling the framework that its name is <code>test_that</code>.</p>
</div>
<h2 id="how-can-we-build-a-commandline-driver-for-our-test-manager">How can we build a command-line driver for our test manager?</h2>
<p>The most important concern in our design is
to keep the files containing tests as simple as possible.
A couple of <code>import</code> statements to get <code>assert</code> and <code>hope</code>
and then one function call per test
is about as simple as it gets:</p>
<pre title="test-add.js"><code class="language-js">import assert from 'assert'
import hope from './hope.js'

hope.test('Sum of 1 and 2', () =&gt; assert((1 + 2) === 3))
</code></pre>
<p>We <em>don't</em> want users to have to list files containing tests explicitly,
so we will load test files <g key="dynamic_loading">dynamically</g>.
While <code>import</code> is usually written as a statement,
it can also be used as an <code>async</code> function
that takes a path as a parameter and loads the corresponding file.
As before,
loading files executes the code they contain,
which registers tests as a <g key="side_effect">side effect</g> via calls to <code>hope.test</code>:</p>
<pre title="pray.js"><code class="language-js">import minimist from 'minimist'
import glob from 'glob'
import hope from './hope.js'

const main = async (args) =&gt; {
  const options = parse(args)
  if (options.filenames.length === 0) {
    options.filenames = glob.sync(`${options.root}/**/test-*.js`)
  }
  for (const f of options.filenames) {
    await import(f)
  }
  hope.run()
  const result = (options.output === 'terse')
    ? hope.terse()
    : hope.verbose()
  console.log(result)
}
...
main(process.argv.slice(2))
</code></pre>
<p>By default,
this program finds all files below the current working directory
whose names match the pattern <code>test-*.js</code>
and uses terse output.
Since we may want to look for files somewhere else,
or request verbose output,
the program needs to handle command-line arguments.</p>
<p>The <a href="https://www.npmjs.com/package/minimist"><code>minimist</code></a> module does this
in a way that is consistent with Unix conventions.
Given command-line arguments <em>after</em> the program's name
(i.e., from <code>process.argv[2]</code> onward),
it looks for patterns like <code>-x something</code>
and creates an object with flags as keys and values associated with them.</p>
<div class="callout">
<h3 id="filenames-in-minimist">Filenames in <code>minimist</code></h3>
<p>If we use a command line like <code>pray.js -v something.js</code>,
then <code>something.js</code> becomes the value of <code>-v</code>.
To indicate that we want <code>something.js</code> added to the list of trailing filenames
associated with the special key <code>_</code> (a single underscore),
we have to write <code>pray.js -v -- something.js</code>.
The double dash is a common Unix convention for signalling the end of parameters.</p>
</div>
<p>Our <g key="test_runner">test runner</g> is now complete,
so we can try it out with some files containing tests that pass, fail, and contain errors:</p>
<pre title="pray.sh"><code class="language-sh">node pray.js -v
</code></pre>
<pre title="pray.out"><code class="language-out">passes:
  /u/stjs/unit-test/test-add.js::Sum of 1 and 2
  /u/stjs/unit-test/test-sub.js::Difference of 1 and 2
fails:
  /u/stjs/unit-test/test-div.js::Quotient of 1 and 0
  /u/stjs/unit-test/test-mul.js::Product of 1 and 2
errors:
  /u/stjs/unit-test/test-missing.js::Sum of x and 0
</code></pre>
<div class="callout">
<h3 id="infinity-is-allowed">Infinity is allowed</h3>
<p><code>test-div.js</code> contains the line:</p>
<pre><code class="language-js">hope.test('Quotient of 1 and 0', () =&gt; assert((1 / 0) === 0))
</code></pre>
<p>This test counts as a failure rather than an error
because thinks the result of dividing by zero is the special value <code>Infinity</code>
rather than an arithmetic error.</p>
</div>
<p>The <g key="lifecycle">lifecycle</g> of a pair of files <code>test-add.js</code> and <code>test-sub.js</code> is
shown in <f key="unit-test-lifecycle"></f>:</p>
<ol>
<li><code>pray</code> loads <code>hope.js</code>.</li>
<li>Loading <code>hope.js</code> creates a single instance of the class <code>Hope</code>.</li>
<li><code>pray</code> uses <code>glob</code> to find files with tests.</li>
<li><code>pray</code> loads <code>test-add.js</code> using <code>import</code> as a function.</li>
<li>As <code>test-add.js</code> runs, it loads <code>hope.js</code>.
Since <code>hope.js</code> is already loaded, this does not create a new instance of <code>Hope</code>.</li>
<li><code>test-add.js</code> uses <code>hope.test</code> to register a test (which does not run yet).</li>
<li><code>pray</code> then loads <code>test-sub.js</code>…</li>
<li>…which loads <code>Hope</code>…</li>
<li>…then registers a test.</li>
<li><code>pray</code> can now ask the unique instance of <code>Hope</code> to run all of the tests,
then get a report from the <code>Hope</code> singleton and display it.</li>
</ol>
<figure id="unit-test-lifecycle"><img src="./figures/lifecycle.svg" alt="Unit testing lifecycle"/><figcaption>Lifecycle of dynamically-discovered unit tests.</figcaption></figure>
<h2 id="exercises">Exercises</h2>
<h3 class="exercise">Asynchronous globbing</h3>
<p>Modify <code>pray.js</code> to use the asynchronous version of <code>glob</code> rather than <code>glob.sync</code>.</p>
<h3 class="exercise">Timing tests</h3>
<p>Install the <a href="https://www.npmjs.com/package/microtime"><code>microtime</code></a> package and then modify the <code>dry-run.js</code> example
so that it records and reports the execution times for tests.</p>
<h3 class="exercise">Approximately equal</h3>
<ol>
<li>
<p>Write a function <code>assertApproxEqual</code> that does nothing if two values are within a certain tolerance of each other
but throws an exception if they are not:</p>
<pre><code class="language-js"># throws exception
assertApproxEqual(1.0, 2.0, 0.01, 'Values are too far apart')

# does not throw
assertApproxEqual(1.0, 2.0, 10.0, 'Large margin of error')
</code></pre>
</li>
<li>
<p>Modify the function so that a default tolerance is used if none is specified:</p>
<pre><code class="language-js"># throws exception
assertApproxEqual(1.0, 2.0, 'Values are too far apart')

# does not throw
assertApproxEqual(1.0, 2.0, 'Large margin of error', 10.0)
</code></pre>
</li>
<li>
<p>Modify the function again so that it checks the <g key="relative_error">relative error</g>
instead of the <g key="absolute_error">absolute error</g>.
(The relative error is the absolute value of the difference between the actual and expected value,
divided by the absolute value.)</p>
</li>
</ol>
<h3 class="exercise">Rectangle overlay</h3>
<p>A windowing application represents rectangles using objects with four values:
<code>x</code> and <code>y</code> are the coordinates of the lower-left corner,
while <code>w</code> and <code>h</code> are the width and height.
All values are non-negative:
the lower-left corner of the screen is at <code>(0, 0)</code>
and the screen's size is <code>WIDTH</code>x<code>HEIGHT</code>.</p>
<ol>
<li>
<p>Write tests to check that an object represents a valid rectangle.</p>
</li>
<li>
<p>The function <code>overlay(a, b)</code> takes two rectangles and returns either
a new rectangle representing the region where they overlap or <code>null</code> if they do not overlap.
Write tests to check that <code>overlay</code> is working correctly.</p>
</li>
<li>
<p>Do you tests assume that two rectangles that touch on an edge overlap or not?
What about two rectangles that only touch at a single corner?</p>
</li>
</ol>
<h3 class="exercise">Selecting tests</h3>
<p>Modify <code>pray.js</code> so that if the user provides <code>-s pattern</code> or <code>--select pattern</code>
then the program only runs tests in files that contain the string <code>pattern</code> in their name.</p>
<h3 class="exercise">Tagging tests</h3>
<p>Modify <code>hope.js</code> so that users can optionally provide an array of strings to tag tests:</p>
<pre><code class="language-js">hope.test('Difference of 1 and 2',
          () =&gt; assert((1 - 2) === -1),
          ['math', 'fast'])
</code></pre>
<p>Then modify <code>pray.js</code> so that if users specify either <code>-t tagName</code> or <code>--tag tagName</code>
only tests with that tag are run.</p>
<h3 class="exercise">Mock objects</h3>
<p>A <g key="mock_object">mock object</g> is a simplified replacement for part of a program
whose behavior is easier to control and predict than the thing it is replacing.
For example,
we may want to test that our program does the right thing if an error occurs while reading a file.
To do this,
we write a function that wraps <code>fs.readFileSync</code>:</p>
<pre><code class="language-js">const mockReadFileSync = (filename, encoding = 'utf-8') =&gt; {
  return fs.readFileSync(filename, encoding)
}
</code></pre>
<div class="continue">
<p>and then modify it so that it throws an exception under our control.
For example,
if we define <code>MOCK_READ_FILE_CONTROL</code> like this:</p>
</div>
<pre><code class="language-js">const MOCK_READ_FILE_CONTROL = [false, false, true, false, true]
</code></pre>
<div class="continue">
<p>then the third and fifth calls to <code>mockReadFileSync</code> throw an exception instead of reading data,
as do any calls after the fifth.
Write this function.</p>
</div>
<h3 class="exercise">Setup and teardown</h3>
<p>Testing frameworks often allow programmers to specify a <code>setup</code> function
that is to be run before each test
and a corresponding <code>teardown</code> function
that is to be run after each test.
(<code>setup</code> usually re-creates complicated test fixtures,
while <code>teardown</code> functions are sometimes needed to clean up after tests,
e.g., to close database connections or delete temporary files.)</p>
<p>Modify the testing framework in this chapter so that
if a file of tests contains something like this:</p>
<pre><code class="language-js">const createFixtures = () =&gt; {
  ...do something...
}

hope.setup(createFixtures)
</code></pre>
<div class="continue">
<p>then the function <code>createFixtures</code> will be called
exactly once before each test in that file.
Add a similar way to register a teardown function with <code>hope.teardown</code>.</p>
</div>
<h3 class="exercise">Multiple tests</h3>
<p>Add a method <code>hope.multiTest</code> that allows users to specify
multiple test cases for a function at once.
For example, this:</p>
<pre><code class="language-js">hope.multiTest('check all of these`, functionToTest, [
  [['arg1a', 'arg1b'], 'result1'],
  [['arg2a', 'arg2b'], 'result2'],
  [['arg3a', 'arg3b'], 'result3']
])
</code></pre>
<div class="continue">
<p>should be equivalent to this:</p>
</div>
<pre><code class="language-js">hope.test('check all of these 0',
  () =&gt; assert(functionToTest('arg1a', 'arg1b') === 'result1')
)
hope.test('check all of these 1',
  () =&gt; assert(functionToTest('arg2a', 'arg2b') === 'result2')
)
hope.test('check all of these 2',
  () =&gt; assert(functionToTest('arg3a', 'arg3b') === 'result3')
)
</code></pre>
<h3 class="exercise">Assertions for sets and maps</h3>
<ol>
<li>
<p>Write functions <code>assertSetEqual</code> and <code>assertMapEqual</code>
that check whether two instances of <code>Set</code> or two instances of <code>Map</code> are equal.</p>
</li>
<li>
<p>Write a function <code>assertArraySame</code>
that checks whether two arrays have the same elements,
even if those elements are in different orders.</p>
</li>
</ol>
<h3 class="exercise">Testing promises</h3>
<p>Modify the unit testing framework to handle <code>async</code> functions,
so that:</p>
<pre><code class="language-js">hope.test('delayed test', async () =&gt; {...})
</code></pre>
<div class="continue">
<p>does the right thing.
(Note that you can use <code>typeof</code> to determine whether the object given to <code>hope.test</code>
is a function or a promise.)</p>
</div>
</main>
<footer>
<div class="row">
<div class="left3">
<a href="../async-programming/"><em>&laquo; Asynchronous Programming</em></a>
</div>
<div class="middle3">
<a href="../license/"><img class="footer" src="../../static/cc-by.svg" alt="License" /></a>
<a href="https://github.com/software-tools-in-javascript/stjs/"><img class="footer" src="../../static/github.svg" alt="Repository" /></a>
© 2020 <a href="../authors/">The Authors</a>
</div>
<div class="right3">
<a href="../file-backup/"><em>File Backup &raquo;</em></a>
</div>
</div>
</footer>
</body>
</html>
